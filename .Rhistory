##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
complexity = complexity + sum(countVector);
}
}
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
complexity
##Process each file
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
}
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
?print
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
print(complexity);
}
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
computeFile(fileName);
}
complexity
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
return (complexity);
}
##Process each file
computeFile <- function(fileName){
dataframe <- readLines(fileName)
##remove empty lines
dataframe <- removeEmptyElements(dataframe);
##TODO remove comments
##TODO remove tabs
##Count complexity factors
factors <- c("if","else","case","default","return","for","while","do-while","break","continue","&&","\\|\\|", "\\?", ":","catch", "finally", "throw", "throws");
complexity = 1;
for(line in dataframe){
line <- sapply(line, tolower);
print(line);
countVector <- str_count(line,factors);
print(sum(countVector));
complexity = complexity + sum(countVector);
}
return (complexity);
}
#Load scripts
baseDir<- "C://Users//chris//OneDrive//Documentos//GitHub//";
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
print("complexity:"+computeFile(fileName));
}
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
print("complexity:",computeFile(fileName));
}
baseDir<- "C://Users//chris//OneDrive//Documentos//GitHub//";
dir<- paste(baseDir, "dataWrangling//dataframeUtil.R",sep="");
source(dir);
dirData <-paste(baseDir, "photinus-analytics//codeSnippetAnalysis//data//",sep="");
fileList <- list.files(dirData, full.names = TRUE);
dataframe <- readLines(fileList[1]);
for(fileName in fileList){
cat("complexity:",computeFile(fileName));
}
?qnorm
qnorm(0.95,0,1,lower.tail = FALSE, log.p = FALSE)
qnorm(95,0,1,lower.tail = FALSE, log.p = FALSE)
qnorm(0.95,0,1,lower.tail = TRUE, log.p = FALSE)
qnorm(0.975,0,1,lower.tail = TRUE, log.p = FALSE)
?dbeta
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,4,0),type="l")
plot(theta,dbeta(theta,4,1),type="l")
plot(theta,dbeta(theta,1,1),type="l")
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,4,2),type="l")
plot(theta,dbeta(theta,0,4),type="l")
?dbeta
plot(theta,dbeta(theta,1,4),type="l")
plot(theta,dbeta(theta,1,5),type="l")
1-pbeta(.25,41,11)
1-pbeta(.5,41,11)
1-pbeta(.8,41,11)
1-pbeta(.5,1,5)
pbeta(.5,1,5)
plot(theta,dbeta(theta,41,11),type="l")
1-pbeta(.5,41,11)
1-pbeta(.8,41,11)
?pbeta
1-pbeta(.8,41,11,lower.tail = TRUE)
1-pbeta(.8,1,5,lower.tail = TRUE)
theta=seq(from=0,to=1,by=.01)
plot(theta,dbeta(theta,1,5),type="l")
pbeta(.5,1,5)
pbeta(.5,1,5)
1- pbeta(.95,8,16)
1- pbeta(0.95,16,8)
qbeta(0.025,8,16)
qbeta(0.975,8,16)
1-pbeta(.8,41,11)
1-pbeta(.5,41,11)
1-pbeta(.25,41,11)
qbeta(.025,41,11)
qbeta(.975,41,11)
qbeta(0.05,8,16)
qbeta(0.95,8,16)
qbeta(0.90,8,16)
?pbeta
pgamma
pgamma
?pgamma
theta=seq(from=0,to=1,by=.01)
plot(theta,gamma(theta,67,6),type="l")
plot(theta,dgamma(theta,67,6),type="l")
plot(theta,dgamma(theta,8,1),type=".")
plot(theta,dgamma(theta,67,6),type="l")
plot(theta,dgamma(theta,8,1),type="-")
plot(theta,dgamma(theta,8,1),type="-")
lines(theta,dgamma(theta,67,6),lty=2)
lines(theta,dgamma(theta,8,1),lty=3
plot(theta,dbeta(theta,32,20),type="l")
lines(theta,dbeta(theta,8,4),lty=2)
lines(theta,44*dbinom(24,size=40,p=theta),lty=3)
plot(theta,dbeta(theta,32,20),type="l")
lines(theta,dbeta(theta,8,4),lty=2)
source('C:/Users/chris/OneDrive/Documentos/GitHub/bayesianStudies/CredibleIntervals.R', echo=TRUE)
plot(theta,dgamma(theta,8,1),type="l")
lines(theta,dgamma(theta,8,1),lty=3)
lines(theta,dgamma(theta,67,6),lty=2)
gam=seq(from=0,to=20,by=1)
plot(theta,dgamma(gam,8,1),type="l")
lines(theta,dgamma(gam,8,1),lty=3)
lines(theta,dgamma(gam,67,6),lty=2)
plot(theta,dgamma(gam,8,1),type="l")
gam=seq(from=0,to=20,by=1)
plot(theta,dgamma(gam,8,1),type="l")
plot(gam,dgamma(gam,8,1),type="l")
lines(gam,dgamma(gam,8,1),lty=3)
lines(gam,dgamma(gam,67,6),lty=2)
plot(gam,dgamma(gam,67,6),type="l")
lines(gam,dgamma(gam,8,1),lty=3)
lines(gam,dgamma(gam,67,6),lty=2)
plot(gam,dgamma(gam,67,6),type="l")
lines(gam,dgamma(gam,8,1),lty=2)
lines(gam,dgamma(gam,67,6),lty=3)
plot(gam,dgamma(gam,67,6),type="l")
lines(gam,dgamma(gam,8,1),lty=2)
qgamma(0.05,67,6)
qgamma(0.95,67,6)
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
plot(dataf$Answer.difficulty,dataf$Code.complexity);
plot(dataf$Answer.difficulty,dataf$Code.LOC);
cor.test(dataf$Answer.difficulty,dataf$Code.LOC)
cor.test(dataf$Answer.difficulty,dataf$Code.complexity)
cor.test(dataf$Answer.difficulty,dataf$Code.LOC) #SIGNIFICANT, BUT WEAK
plot(dataf$Code.LOC,dataf$Code.complexity);
cor.test(dataf$Code.LOC,dataf$Code.complexity) #SIGNIFICANT, BUT WEAK
plot(dataf$Answer.difficulty,dataf$Answer.confidence);
cor.test(dataf$Aswer.confidence,dataf$Answer.difficulty) #SIGNIFICANT, STRONG
size(dataf$Answer.difficulty)
length(dataf$Answer.difficulty)
length(dataf$Answer.confidence)
cor.test(dataf$Aswer.confidence,dataf$Answer.difficulty) #SIGNIFICANT, STRONG
cor.test(dataf$Aswer.confidence,dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Code.LOC,dataf$Code.complexity,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,,method="kendall") #NOT SIGNIFICANT
cor.test(dataf$Aswer.confidence,dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
length(dataf$Answer.confidence) == length(dataf$Answer.difficulty)
length(dataf$Answer.confidence)
length(dataf$Answer.difficulty)
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
length(dataf$Answer.confidence) == length(dataf$Answer.difficulty)
length(dataf$Answer.confidence)
loadAnswers
dataf <- loadAnswers("answerList_data.csv");
length(dataf$Answer.confidence)
source('C:/Users/chris/OneDrive/Documentos/GitHub/workerConfidenceTrees/loadAnswers.R', echo=TRUE)
dataf <- loadAnswers("answerList_data.csv");
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
length(dataf$Answer.confidence)
cor.test(dataf$Aswer.confidence,dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Code.LOC,dataf$Code.complexity,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Aswer.difficulty, dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Answer.confidence, dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
length(dataf$Answer.confidence)
length(dataf$Answer.confidence)
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
length(dataf$Answer.confidence)
cor.test(dataf$Answer.confidence, dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Code.LOC,dataf$Code.complexity,method="kendall") #SIGNIFICANT, STRONG
source('C:/Users/chris/OneDrive/Documentos/GitHub/workerConfidenceTrees/loadAnswers.R', echo=TRUE)
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
cor.test(dataf$Answer.confidence, dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
#Load Answers into a dataframe
#It also removes invalid input and outliers)
loadAnswers<- function(fileName){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//");
data_all <- read.csv(fileName,header = TRUE,sep=",");
dataf = data.frame(data_all);
#summary(dataf)
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with empty data
#dataf <- dataf [!(dataf$Worker.age==0),];
#Remove confidence level zero (because it is associated with IDK answers)
dataf <- dataf [!(dataf$Answer.confidence==0) ,];
dataf <- dataf [!(dataf$Answer.confidence==3) ,];
#Remove invalid values
#dataf <- dataf [!dataf$Worker.age <1,];
#dataf <- dataf [!dataf$Worker.yearsOfExperience <1,];
#Outliers
#Assuming that the youngest age to start programming is 10 years old
#Remove inputs for which age-YoE<5
#dataf <- removeLinesColDiffSmallerThanValue(dataf,7,5,10)
#summary (dataf);
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
cor.test(dataf$Answer.confidence, dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
# Import data
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
cor.test(dataf$Answer.confidence, dataf$Answer.difficulty,method="kendall") #SIGNIFICANT, STRONG
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,,method="kendall") #SIGNIFICANT, BUT WEAK
dataf <- loadAnswers("answerList_data.csv");
summary(dataf$Answer.confidence)
dataf$Worker.profession = as.factor(dataf$Worker.profession)
set.seed(9850)
g<- runif((nrow(dataf))) #generates a random distribution
dataf.rows <- dataf[order(g),]
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:1806,], method="class")
rpart.plot(model1)
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:1806,], method="class")
rpart.plot(model1)
model2 = rpart(Answer.confidence ~ Code.LOC, data = dataf.rows[1:1806,], method="class")
rpart.plot(model2)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:1806,], method="class")
rpart.plot(model3)
model4 = rpart(Answer.difficulty ~ Code.complexity, data = dataf.rows[1:1806,], method="class")
rpart.plot(model4)
#Load Answers into a dataframe
#It also removes invalid input and outliers)
loadAnswers<- function(fileName){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//");
data_all <- read.csv(fileName,header = TRUE,sep=",");
dataf = data.frame(data_all);
#summary(dataf)
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with empty data
#dataf <- dataf [!(dataf$Worker.age==0),];
#Remove confidence level zero (because it is associated with IDK answers)
#dataf <- dataf [!(dataf$Answer.confidence==0) ,];
#dataf <- dataf [!(dataf$Answer.confidence==3) ,];
#Remove NO AND IDK ANSWERS
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
dataf <- dataf [!(dataf$Answer.option=="NO") ,];
#Remove invalid values
#dataf <- dataf [!dataf$Worker.age <1,];
#dataf <- dataf [!dataf$Worker.yearsOfExperience <1,];
#Outliers
#Assuming that the youngest age to start programming is 10 years old
#Remove inputs for which age-YoE<5
#dataf <- removeLinesColDiffSmallerThanValue(dataf,7,5,10)
#summary (dataf);
return(dataf);
}
# Import data
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
summary(dataf)
dataf <- dataf [!(dataf$Answer.option==NO) ,];
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
source('C:/Users/chris/OneDrive/Documentos/GitHub/workerConfidenceTrees/loadAnswers.R', echo=TRUE)
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
summary(dataf$Answer.confidence)
dataf$Worker.profession = as.factor(dataf$Worker.profession)
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
summary(dataf$Answer.option)
#Load Answers into a dataframe
#It also removes invalid input and outliers)
loadAnswers<- function(fileName){
setwd("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//");
data_all <- read.csv(fileName,header = TRUE,sep=",");
dataf = data.frame(data_all);
#summary(dataf)
#First I need to look at the outliers or invalid values
#Invalid age and invalid years of experience
#Remove rows with empty data
#dataf <- dataf [!(dataf$Worker.age==0),];
#Remove confidence level zero (because it is associated with IDK answers)
#dataf <- dataf [!(dataf$Answer.confidence==0) ,];
#dataf <- dataf [!(dataf$Answer.confidence==3) ,];
#Remove NO AND IDK ANSWERS
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
dataf <- dataf [!(dataf$Answer.option=="NO") ,];
#Remove invalid values
#dataf <- dataf [!dataf$Worker.age <1,];
#dataf <- dataf [!dataf$Worker.yearsOfExperience <1,];
#Outliers
#Assuming that the youngest age to start programming is 10 years old
#Remove inputs for which age-YoE<5
#dataf <- removeLinesColDiffSmallerThanValue(dataf,7,5,10)
#summary (dataf);
return(dataf);
}
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
##
# Import data
dataf <- loadAnswers("answerList_data.csv");
summary(dataf$Answer.confidence)
##
# Train model
# Treat worker profession as factor (categorical data)
dataf$Worker.profession = as.factor(dataf$Worker.profession)
summary(dataf$Answer.option)
set.seed(9850)
g<- runif((nrow(dataf))) #generates a random distribution
dataf.rows <- dataf[order(g),]
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:450,], method="class")
rpart.plot(model1)
model2 = rpart(Answer.confidence ~ Code.LOC, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
model2 = rpart(Answer.confidence ~ Code.LOC + Code.Complexity, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:450,], method="class")
rpart.plot(model1)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:1806,], method="class")
rpart.plot(model3)
model4 = rpart(Answer.difficulty ~ Code.complexity, data = dataf.rows[1:1806,], method="class")
rpart.plot(model4)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:450,], method="class")
rpart.plot(model3)
model4 = rpart(Answer.difficulty ~ Code.complexity, data = dataf.rows[1:1450,], method="class")
rpart.plot(model4)
model4 = rpart(Answer.difficulty ~ Code.complexity + Code.LOC, data = dataf.rows[1:1450,], method="class")
rpart.plot(model4)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:450,], method="class")
rpart.plot(model3)
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:450,], method="class")
rpart.plot(model1)
model2 = rpart(Answer.confidence ~ Code.LOC + Code.Complexity, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
model2 = rpart(Answer.confidence ~ Code.Complexity, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
model2 = rpart(Answer.confidence ~ Code.complexity, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
model2 = rpart(Answer.confidence ~ Code.LOC + Code.complexity, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
model2 = rpart(Answer.confidence ~ Code.complexity + Code.LOC, data = dataf.rows[1:450,], method="class")
rpart.plot(model2)
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
##
# Import data
dataf <- loadAnswers("answerList_data.csv");
summary(dataf$Answer.confidence)
##
# Train model
# Treat worker profession as factor (categorical data)
dataf$Worker.profession = as.factor(dataf$Worker.profession)
summary(dataf$Answer.option)
#Shuffle randomly the rows in the dataset
set.seed(9850)
g<- runif((nrow(dataf))) #generates a random distribution
dataf.rows <- dataf[order(g),]
summary(dataf$Answer.option)
1620*0.7
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:1134,], method="class")
rpart.plot(model1)
model2 = rpart(Answer.confidence ~ Code.complexity + Code.LOC, data = dataf.rows[1:1340,], method="class")
rpart.plot(model2)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:450,], method="class")
rpart.plot(model3)
model4 = rpart(Answer.difficulty ~ Code.complexity + Code.LOC, data = dataf.rows[1:1450,], method="class")
rpart.plot(model4)
model2 = rpart(Answer.confidence ~ Code.complexity + Code.LOC, data = dataf.rows[1:1134,], method="class")
rpart.plot(model2)
model2 = rpart(Answer.confidence ~ Code.complexity , data = dataf.rows[1:1134,], method="class")
rpart.plot(model2)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:1134,], method="class")
rpart.plot(model3)
model4 = rpart(Answer.difficulty ~ Code.complexity + Code.LOC, data = dataf.rows[1:1134,], method="class")
rpart.plot(model4)
model4 = rpart(Answer.difficulty ~ Code.complexity + Code.LOC, data = dataf.rows[1:1134,], method="class")
rpart.plot(model4)
dataf.rows <- dataf[order(g),]
model4 = rpart(Answer.difficulty ~ Code.complexity + Code.LOC, data = dataf.rows[1:1134,], method="class")
rpart.plot(model4)
model3 = rpart(Answer.difficulty ~ Worker.profession + Worker.score, data = dataf.rows[1:1134,], method="class")
rpart.plot(model3)
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:1134,], method="class")
rpart.plot(model1)
model2 = rpart(Answer.confidence ~ Code.complexity + Code.LOC, data = dataf.rows[1:1134,], method="class")
rpart.plot(model2)
rpart.plot(model1, type=3, extra=101, fallen.leaves = T)
rpart.plot(model2, type=3, extra=101, fallen.leaves = T)
p1 <- predict(model2, dataf.rows[1135:1640,], type="class")
table(dataf.rows[1135:1640,4],predicted=p1)
model1 = rpart(Answer.confidence ~ Worker.profession + Worker.score, data = dataf.rows[1:1134,], method="class")
rpart.plot(model1)
p1 <- predict(model1, dataf.rows[1135:1640,], type="class")
table(dataf.rows[1135:1640,4],predicted=p1)
?randomForest
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,method="kendall") #SIGNIFICANT, BUT WEAK
dataf <- loadAnswers("answerList_data.csv");
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
dataf <- dataf [!(dataf$Answer.option=="YES") ,];
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,method="kendall") #SIGNIFICANT, BUT WEAK
dataf <- loadAnswers("answerList_data.csv");
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
dataf <- dataf [!(dataf$Answer.option=="NO") ,];
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,method="kendall") #SIGNIFICANT, BUT WEAK
source("C://Users//chris//OneDrive//Documentos//GitHub//workerConfidenceTrees//loadAnswers.R");
dataf <- loadAnswers("answerList_data.csv");
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
dataf <- dataf [!(dataf$Answer.option=="NO") ,];
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,method="kendall") #SIGNIFICANT, BUT WEAK
dataf <- loadAnswers("answerList_data.csv");
summary(dataf)
dataf <- dataf [!(dataf$Answer.option=="IDK") ,];
dataf <- dataf [!(dataf$Answer.option=="YES") ,];
cor.test(dataf$Answer.difficulty,dataf$Code.LOC,method="kendall") #SIGNIFICANT, BUT WEAK
cor.test(dataf$Answer.difficulty,dataf$Code.complexity,method="kendall") #SIGNIFICANT, BUT WEAK
